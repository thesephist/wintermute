---
title: "The rights to become"
date: 2015-05-23T00:00:00-00:00
location: "West Lafayette, IN"
---

It's often said that a mature chimp or a dolphin probably has a higher cognitive ability than a newborn baby, or even one that's around a year old. They usually have similar capacities to feel emotion, to notice how others are feeling, and react accordingly. They can count, express their ideas with some form of language, and learn rapidly. _But_, despite the fact that both a chimp and a newborn child are somewhat similar in how they _can_ interact with the rest of humanity, we view them completely differently. The murder of a human child, for example, is a serious crime, no matter how old the child. But the killing of a chimp is a light crime at best, and ends at "you probably shouldn't do that" at worst. Children, no matter how young or disprivileged, have certain _rights_ -- rights to which they are entitled merely because they happen to be of the same species as the rest of us. I'm not saying children don't deserve those rights -- they are called "unalienable" for a reason. But I do think it's important to notice that our treatment of beings -- humans, animals, and even machines -- currently depend almost exclusively on how _we_ view them, not on what or who they are, nor on what skills they have or what they can offer us and the world. Only our relationships and our perspectives as humans determine how we treat them -- as beings with their own will, property, and rights; or as objects, only to be possessed and exploited.

That fact is increasingly important, not only because of the relevance of animal rights, but because of the increasing dependence of human industries on machines. Sci-Fi novelist Isaac Asimov first used the term "robot" when machines were more like clumps of metal engineered to take over dangerous jobs in factories and manufacturing. They weren't complex and versatile puzzles of circuitry that we go so far as to call "beautiful" or "intelligent". The concept of an _intelligent machine_ was unfathomable at the time.

But jump forward a few centuries, and Google can read house numbers just as well as a human from a picture -- only several thousand times faster. Self-driving cars only get in accidents because their human drivers make mistakes. Software composes classical music in seconds. Programs can extrapolate from millions of data points faster than any human being. And they can learn to respond to social situations and facial expressions of others. By many measures -- if not most of them -- computer software has enough cognitive ability to be considered equally capable as a newborn or a chimp; they are equally capable in expressing emotions, responding to stimuli, learning, and even doing complex tasks like vision and hearing. And if the advancement of a few dozen years can create so much, it's not so far-fetched to imagine a decade, somewhat like the society in Spike Jonze's film _Her_, where computers carry a certain degree of _humanness_, and humans form emotional attachment and relevance to "objects" that aren't _biologically_ human.

At the current moment, the only "things" or "beings" that can have rights -- legal protections to freedom and free will -- are biological human beings. Animals, no matter how human-like, can't have rights. They are, in legal terms, objects, just as capable of free will as a Kleenex box or Siri, which is to say, not at all. Human rights are currently given, as I said, based on how human beings relate to and feel about other objects or beings, rather than what or who they are, and what they're capable of. And because our current view of computers and machine intelligence is more as "tin cans that can read" than "intelligent beings in the form of metal and wires", we choose to consider them objects incapable of having rights. And at the present moment, that's valid.

But with such a rapid pace of innovation, in a few decades, we undoubtedly _will_ have computers capable of sympathy and emotional response, like the one we see in _Her_. And when we do, we'll be lead to treat those "devices" or "programs" more like human beings than like toys or machines. We'll talk to them, share our feelings, and perhaps even love them, because they will (or, at the very least, will appear to) return our love. And at that point, computer software will have met our criteria for deserving human rights -- we will interact with them as we would with a human being. When we are just as attached to the companionship of a human-like, amiable robot as we are to each other, we'll care when another being harms or "kills" our robots. We'll be upset that the robots have to constantly abide by human commands. In other words, with the inception of computers capable of human connection, our view on robots will escape from the "tool" category into the "slave" category, and we _will_ care that they have rights. Because _we grant rights based on how we relate to their recipients, above all else._

Let's put it this way: there is overwhelming scientific evidence that a chimp has just as much of a desire to determine their own fate as a child. And yet, we grant children the basic human rights merely because we _feel_ connected to them. And by being connected to them, we feel a sense of care and responsibility -- care and responsibility based on our interactions with them. When -- not an _if_, but a _when_ -- computers become capable of the same human connections we form with each other, we would have no choice but to grant certain intelligent computers the same basic "human" rights we now grant only to biological humans. After all, if a computer with whose voice and presence you've spent all your childhood were to be suddenly destroyed or sold, can you not imagine yourself being upset? The boundary won't be between robots and humans, but between intelligent robots and "unintelligent" ones. The lines of human rights won't be drawn between different races or genders, nor even between humans and non-humans, but between machines and other machines. And while it sounds far-fetched and reminiscent of science fiction, the fact that you've talked to a computer in the last few months is proving to us that it's not.
